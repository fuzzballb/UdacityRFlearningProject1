{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==0.4.0 (from unityagents==0.4.0) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)\n",
      "ERROR: No matching distribution found for torch==0.4.0 (from unityagents==0.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below.  Please run the next code cell without making any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# please do not modify the line below\n",
    "env = UnityEnvironment(file_name=\"Banana_Windows_x86_64/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agent while it is training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Episode 47\tAverage Score: 1.406"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fbddd6590683>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Start\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-fbddd6590683>\u001b[0m in \u001b[0;36mdqn\u001b[1;34m(n_episodes, max_t, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;31m# 3. change to a version of agent.act\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Clients\\Udacity\\Github\\UdacityRFlearningProject1\\dqn_agent.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;31m# If enough samples are available in memory, get random subset and learn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                 \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Clients\\Udacity\\Github\\UdacityRFlearningProject1\\dqn_agent.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mrewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\UdacityRLProject1\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "# state = env_info.vector_observations[0]            # get the current state\n",
    "# score = 0                                          # initialize the score\n",
    "# while True:\n",
    "#     action = np.random.randint(action_size)        # select an action\n",
    "#     env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "#     next_state = env_info.vector_observations[0]   # get the next state\n",
    "#     reward = env_info.rewards[0]                   # get the reward\n",
    "#     done = env_info.local_done[0]                  # see if episode has finished\n",
    "#     score += reward                                # update the score\n",
    "#     state = next_state                             # roll over the state to next time step\n",
    "#     if done:                                       # exit loop if episode finished\n",
    "#         break\n",
    "    \n",
    "# print(\"Score: {}\".format(score))\n",
    "\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dqn_agent import Agent\n",
    "\n",
    "# initialise an agent\n",
    "agent = Agent(state_size=37, action_size=4, seed=0)\n",
    "\n",
    "\n",
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.905):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        # state = env.reset()\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]            # get the current state\n",
    "        \n",
    "        \n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            \n",
    "            #print(\"action\")\n",
    "            # action = agent.act(state, eps)\n",
    "            # action = np.random.randint(action_size)        # select a random action\n",
    "            \n",
    "            # 1. change to a version of agent.act\n",
    "            action = agent.act(state, eps)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #next_state, reward, done, _ = env.step(action)\n",
    "            #print(\"next_state\")\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            # agent.step(state, action, reward, next_state, done)\n",
    "            #print(\"env_info\")\n",
    "            \n",
    "            \n",
    "            # 2. do the step in the actual environment, and recieve a next state and reward\n",
    "            env_info = env.step(action.astype(int))[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            \n",
    "            \n",
    "            # 3. change to a version of agent.act\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            \n",
    "            \n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            \n",
    "            # AB : moved below step\n",
    "            \n",
    "            #print(done)\n",
    "            \n",
    "            \n",
    "            #print(\".\")\n",
    "            if done:\n",
    "                #print(\"Episode done\")\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if  i_episode == 1400:\n",
    "            break\n",
    "            \n",
    "            \n",
    "            \n",
    "        #if np.mean(scores_window)>=200.0:\n",
    "        #    print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "        #    torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "        #    break\n",
    "    return scores\n",
    "\n",
    "print(\"Start\")\n",
    "scores = dqn()\n",
    "\n",
    "\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agent while it is training.  However, **_after training the agent_**, you can download the saved model weights to watch the agent on your own machine! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
